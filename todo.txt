possible Bias?
    Done- No always predict the last node

get more info
    mail other papers writers - how they do the online predict - does it always on the last node as well ?
    check other papers evaluations - do they add info about how they generate seq data, how they test and evaluate ?

Time OF run
    Check with Bracha = possibility to get a machine with GPU/ how to run with GPU ?
    Tool long even on yoochoose 1/64
    ? Run yoochoose with TS vs pytorch - time f Run ; Problem - TF dees not run
    Consider less epoches then the default ; default --epoch 30
    get diginetica - prepare and run
    use less Data
    Run once on all data - all epoch

Add improvement
    Done - in the data prep / where adding sub seq - Check where the tested node is selected -  data Preparation - or test
    add the nodes in the train
    add an option to OK EOS node in the validation
    how o identify EOS items ?
        negative item ids ?
    how many EOS items to add
        add a few options and test Learn this
    how to compare results
        check that we have the same error on test w/o last click ?
        test on all data, and add constant error for the last click when running w/o improvement ? (bcz it is always wrong / had no way 'to be correct' (mainly in online mode)
    Where to add the new items ?
        Done - Both - in train only  ? in test and train ?
    Done - Add parameter for min item usage and min seq


Research
    check how many real end items exits, and how many usages are there for each (histogram)
    Add parameter for min num of itemd in seq (seq len --> accuracy)
    Add parameter for min item usage ( min item usage --> accuracy)
    num of epochs --> accuracy

general dev
    Done - Add print to file
    make TF run

to understand
    What is the loss vs the recall and the mmr

